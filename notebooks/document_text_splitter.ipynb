{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ca3ad4",
   "metadata": {},
   "source": [
    "### Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a414529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331c14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code = \"\"\"\n",
    "import numpy as np\n",
    "from typing import List, Optional\n",
    "\n",
    "def calculate_mean(numbers: List[float]) -> float:\n",
    "    '''Calculate the arithmetic mean of a list of numbers.\n",
    "    \n",
    "    Args:\n",
    "        numbers: List of numerical values\n",
    "        \n",
    "    Returns:\n",
    "        The mean value\n",
    "    '''\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "def calculate_median(numbers: List[float]) -> float:\n",
    "    '''Calculate the median of a list of numbers.'''\n",
    "    sorted_nums = sorted(numbers)\n",
    "    n = len(sorted_nums)\n",
    "    mid = n // 2\n",
    "    \n",
    "    if n % 2 == 0:\n",
    "        return (sorted_nums[mid - 1] + sorted_nums[mid]) / 2\n",
    "    return sorted_nums[mid]\n",
    "\n",
    "class StatisticalAnalyzer:\n",
    "    '''A class for performing statistical analysis on datasets.'''\n",
    "    \n",
    "    def __init__(self, data: List[float]):\n",
    "        self.data = data\n",
    "        self.mean = None\n",
    "        self.median = None\n",
    "    \n",
    "    def analyze(self) -> dict:\n",
    "        '''Perform complete statistical analysis.'''\n",
    "        self.mean = calculate_mean(self.data)\n",
    "        self.median = calculate_median(self.data)\n",
    "        \n",
    "        return {\n",
    "            'mean': self.mean,\n",
    "            'median': self.median,\n",
    "            'count': len(self.data)\n",
    "        }\n",
    "    \n",
    "    def get_summary(self) -> str:\n",
    "        '''Return a formatted summary of the analysis.'''\n",
    "        if self.mean is None:\n",
    "            self.analyze()\n",
    "        \n",
    "        return f\"Mean: {self.mean:.2f}, Median: {self.median:.2f}\"\n",
    "\n",
    "def main():\n",
    "    '''Main execution function.'''\n",
    "    data = [1.5, 2.3, 3.7, 4.2, 5.1]\n",
    "    analyzer = StatisticalAnalyzer(data)\n",
    "    results = analyzer.analyze()\n",
    "    print(analyzer.get_summary())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "790a993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import numpy as np\n",
      "from typing import List, Optional\n",
      "\n",
      "def calculate_mean(numbers: List[float]) -> float:\n",
      "    '''Calculate the arithmetic mean of a list of numbers.\n",
      "\n",
      "    Args:\n",
      "        numbers: List of numerical values\n",
      "\n",
      "    Returns:\n",
      "        The mean value\n",
      "    '''\n",
      "    return sum(numbers) / len(numbers)\n",
      "\n",
      "def calculate_median(numbers: List[float]) -> float:\n",
      "    '''Calculate the median of a list of numbers.'''\n",
      "    sorted_nums = sorted(numbers)\n",
      "    n = len(sorted_nums)\n",
      "    mid = n // 2\n",
      "\n",
      "    if n % 2 == 0:\n",
      "        return (sorted_nums[mid - 1] + sorted_nums[mid]) / 2\n",
      "    return sorted_nums[mid]\n",
      "\n",
      "class StatisticalAnalyzer:\n",
      "    '''A class for performing statistical analysis on datasets.'''\n",
      "\n",
      "    def __init__(self, data: List[float]):\n",
      "        self.data = data\n",
      "        self.mean = None\n",
      "        self.median = None\n",
      "\n",
      "    def analyze(self) -> dict:\n",
      "        '''Perform complete statistical analysis.'''\n",
      "        self.mean = calculate_mean(self.data)\n",
      "        self.median = calculate_median(self.data)\n",
      "\n",
      "        return {\n",
      "            'mean': self.mean,\n",
      "            'median': self.median,\n",
      "            'count': len(self.data)\n",
      "        }\n",
      "\n",
      "    def get_summary(self) -> str:\n",
      "        '''Return a formatted summary of the analysis.'''\n",
      "        if self.mean is None:\n",
      "            self.analyze()\n",
      "\n",
      "        return f\"Mean: {self.mean:.2f}, Median: {self.median:.2f}\"\n",
      "\n",
      "def main():\n",
      "    '''Main execution function.'''\n",
      "    data = [1.5, 2.3, 3.7, 4.2, 5.1]\n",
      "    analyzer = StatisticalAnalyzer(data)\n",
      "    results = analyzer.analyze()\n",
      "    print(analyzer.get_summary())\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(python_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce62438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the splitter\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=700,\n",
    "    chunk_overlap=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3e4a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"import numpy as np\\nfrom typing import List, Optional\\n\\ndef calculate_mean(numbers: List[float]) -> float:\\n    '''Calculate the arithmetic mean of a list of numbers.\\n\\n    Args:\\n        numbers: List of numerical values\\n\\n    Returns:\\n        The mean value\\n    '''\\n    return sum(numbers) / len(numbers)\\n\\ndef calculate_median(numbers: List[float]) -> float:\\n    '''Calculate the median of a list of numbers.'''\\n    sorted_nums = sorted(numbers)\\n    n = len(sorted_nums)\\n    mid = n // 2\\n\\n    if n % 2 == 0:\\n        return (sorted_nums[mid - 1] + sorted_nums[mid]) / 2\\n    return sorted_nums[mid]\", \"class StatisticalAnalyzer:\\n    '''A class for performing statistical analysis on datasets.'''\\n\\n    def __init__(self, data: List[float]):\\n        self.data = data\\n        self.mean = None\\n        self.median = None\\n\\n    def analyze(self) -> dict:\\n        '''Perform complete statistical analysis.'''\\n        self.mean = calculate_mean(self.data)\\n        self.median = calculate_median(self.data)\\n\\n        return {\\n            'mean': self.mean,\\n            'median': self.median,\\n            'count': len(self.data)\\n        }\\n\\n    def get_summary(self) -> str:\\n        '''Return a formatted summary of the analysis.'''\\n        if self.mean is None:\\n            self.analyze()\", 'return f\"Mean: {self.mean:.2f}, Median: {self.median:.2f}\"', 'def main():\\n    \\'\\'\\'Main execution function.\\'\\'\\'\\n    data = [1.5, 2.3, 3.7, 4.2, 5.1]\\n    analyzer = StatisticalAnalyzer(data)\\n    results = analyzer.analyze()\\n    print(analyzer.get_summary())\\n\\nif __name__ == \"__main__\":\\n    main()']\n"
     ]
    }
   ],
   "source": [
    "# split the code\n",
    "\n",
    "code_chunks = python_splitter.split_text(python_code)\n",
    "\n",
    "print(code_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7887c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, COLORS\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce859c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_chunks(chunks):\n",
    "    colors_list = list(COLORS.keys())[2:8]\n",
    "    print(f\"Total Number of Chunks: {len(chunks)}\")\n",
    "    for num, chunk in enumerate(chunks, 1):\n",
    "        print(f\"Chunk {num}: Length {len(chunk)} chars\")\n",
    "        print(colored(text=chunk, color=choice(colors_list)), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f5f7b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Chunks: 4\n",
      "Chunk 1: Length 592 chars\n",
      "\u001b[35mimport numpy as np\n",
      "from typing import List, Optional\n",
      "\n",
      "def calculate_mean(numbers: List[float]) -> float:\n",
      "    '''Calculate the arithmetic mean of a list of numbers.\n",
      "\n",
      "    Args:\n",
      "        numbers: List of numerical values\n",
      "\n",
      "    Returns:\n",
      "        The mean value\n",
      "    '''\n",
      "    return sum(numbers) / len(numbers)\n",
      "\n",
      "def calculate_median(numbers: List[float]) -> float:\n",
      "    '''Calculate the median of a list of numbers.'''\n",
      "    sorted_nums = sorted(numbers)\n",
      "    n = len(sorted_nums)\n",
      "    mid = n // 2\n",
      "\n",
      "    if n % 2 == 0:\n",
      "        return (sorted_nums[mid - 1] + sorted_nums[mid]) / 2\n",
      "    return sorted_nums[mid]\u001b[0m\n",
      "\n",
      "Chunk 2: Length 675 chars\n",
      "\u001b[35mclass StatisticalAnalyzer:\n",
      "    '''A class for performing statistical analysis on datasets.'''\n",
      "\n",
      "    def __init__(self, data: List[float]):\n",
      "        self.data = data\n",
      "        self.mean = None\n",
      "        self.median = None\n",
      "\n",
      "    def analyze(self) -> dict:\n",
      "        '''Perform complete statistical analysis.'''\n",
      "        self.mean = calculate_mean(self.data)\n",
      "        self.median = calculate_median(self.data)\n",
      "\n",
      "        return {\n",
      "            'mean': self.mean,\n",
      "            'median': self.median,\n",
      "            'count': len(self.data)\n",
      "        }\n",
      "\n",
      "    def get_summary(self) -> str:\n",
      "        '''Return a formatted summary of the analysis.'''\n",
      "        if self.mean is None:\n",
      "            self.analyze()\u001b[0m\n",
      "\n",
      "Chunk 3: Length 58 chars\n",
      "\u001b[36mreturn f\"Mean: {self.mean:.2f}, Median: {self.median:.2f}\"\u001b[0m\n",
      "\n",
      "Chunk 4: Length 230 chars\n",
      "\u001b[31mdef main():\n",
      "    '''Main execution function.'''\n",
      "    data = [1.5, 2.3, 3.7, 4.2, 5.1]\n",
      "    analyzer = StatisticalAnalyzer(data)\n",
      "    results = analyzer.analyze()\n",
      "    print(analyzer.get_summary())\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_chunks(code_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3178a4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nclass ', '\\ndef ', '\\n\\tdef ', '\\n\\n', '\\n', ' ', '']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_splitter.get_separators_for_language(Language.PYTHON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c23911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n#{1,6} ',\n",
       " '```\\n',\n",
       " '\\n\\\\*\\\\*\\\\*+\\n',\n",
       " '\\n---+\\n',\n",
       " '\\n___+\\n',\n",
       " '\\n\\n',\n",
       " '\\n',\n",
       " ' ',\n",
       " '']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_splitter.get_separators_for_language(Language.MARKDOWN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f714ea0",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c0da1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_DATA = {\n",
    "    \"company\": \"AI Research Corp\",\n",
    "    \"departments\": [\n",
    "        {\n",
    "            \"name\": \"Machine Learning\",\n",
    "            \"team_size\": 25,\n",
    "            \"projects\": [\n",
    "                {\n",
    "                    \"id\": \"ML001\",\n",
    "                    \"title\": \"Computer Vision System\",\n",
    "                    \"description\": \"Developing advanced image recognition using CNNs\",\n",
    "                    \"status\": \"active\",\n",
    "                    \"team_members\": [\"Alice\", \"Bob\", \"Charlie\"]\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"ML002\",\n",
    "                    \"title\": \"NLP Platform\",\n",
    "                    \"description\": \"Building transformer-based language models\",\n",
    "                    \"status\": \"active\",\n",
    "                    \"team_members\": [\"David\", \"Eve\"]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Data Engineering\",\n",
    "            \"team_size\": 15,\n",
    "            \"projects\": [\n",
    "                {\n",
    "                    \"id\": \"DE001\",\n",
    "                    \"title\": \"Data Pipeline\",\n",
    "                    \"description\": \"ETL pipeline for real-time data processing\",\n",
    "                    \"status\": \"active\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"technologies\": {\n",
    "        \"frameworks\": [\"TensorFlow\", \"PyTorch\", \"scikit-learn\"],\n",
    "        \"languages\": [\"Python\", \"R\", \"Julia\"],\n",
    "        \"cloud\": [\"AWS\", \"Google Cloud\", \"Azure\"]\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"founded\": 2020,\n",
    "        \"headquarters\": \"San Francisco\",\n",
    "        \"employees\": 150\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef6eafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5931d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the json splitter\n",
    "\n",
    "json_splitter = RecursiveJsonSplitter(\n",
    "    max_chunk_size=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3364ea6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'company': 'AI Research Corp', 'departments': [{'name': 'Machine Learning', 'team_size': 25, 'projects': [{'id': 'ML001', 'title': 'Computer Vision System', 'description': 'Developing advanced image recognition using CNNs', 'status': 'active', 'team_members': ['Alice', 'Bob', 'Charlie']}, {'id': 'ML002', 'title': 'NLP Platform', 'description': 'Building transformer-based language models', 'status': 'active', 'team_members': ['David', 'Eve']}]}, {'name': 'Data Engineering', 'team_size': 15, 'projects': [{'id': 'DE001', 'title': 'Data Pipeline', 'description': 'ETL pipeline for real-time data processing', 'status': 'active'}]}]}, {'technologies': {'frameworks': ['TensorFlow', 'PyTorch', 'scikit-learn'], 'languages': ['Python', 'R', 'Julia'], 'cloud': ['AWS', 'Google Cloud', 'Azure']}}, {'metadata': {'founded': 2020, 'headquarters': 'San Francisco', 'employees': 150}}]\n"
     ]
    }
   ],
   "source": [
    "# return dictionaries\n",
    "\n",
    "chunks_dict = json_splitter.split_json(json_data=JSON_DATA)\n",
    "\n",
    "print(chunks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7df01e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"company\": \"AI Research Corp\", \"departments\": [{\"name\": \"Machine Learning\", \"team_size\": 25, \"projects\": [{\"id\": \"ML001\", \"title\": \"Computer Vision System\", \"description\": \"Developing advanced image recognition using CNNs\", \"status\": \"active\", \"team_members\": [\"Alice\", \"Bob\", \"Charlie\"]}, {\"id\": \"ML002\", \"title\": \"NLP Platform\", \"description\": \"Building transformer-based language models\", \"status\": \"active\", \"team_members\": [\"David\", \"Eve\"]}]}, {\"name\": \"Data Engineering\", \"team_size\": 15, \"projects\": [{\"id\": \"DE001\", \"title\": \"Data Pipeline\", \"description\": \"ETL pipeline for real-time data processing\", \"status\": \"active\"}]}]}', '{\"technologies\": {\"frameworks\": [\"TensorFlow\", \"PyTorch\", \"scikit-learn\"], \"languages\": [\"Python\", \"R\", \"Julia\"], \"cloud\": [\"AWS\", \"Google Cloud\", \"Azure\"]}}', '{\"metadata\": {\"founded\": 2020, \"headquarters\": \"San Francisco\", \"employees\": 150}}']\n"
     ]
    }
   ],
   "source": [
    "# return json text\n",
    "\n",
    "chunks = json_splitter.split_text(JSON_DATA)\n",
    "\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e7858be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Chunks: 3\n",
      "Chunk 1: Length 635 chars\n",
      "\u001b[35m{\"company\": \"AI Research Corp\", \"departments\": [{\"name\": \"Machine Learning\", \"team_size\": 25, \"projects\": [{\"id\": \"ML001\", \"title\": \"Computer Vision System\", \"description\": \"Developing advanced image recognition using CNNs\", \"status\": \"active\", \"team_members\": [\"Alice\", \"Bob\", \"Charlie\"]}, {\"id\": \"ML002\", \"title\": \"NLP Platform\", \"description\": \"Building transformer-based language models\", \"status\": \"active\", \"team_members\": [\"David\", \"Eve\"]}]}, {\"name\": \"Data Engineering\", \"team_size\": 15, \"projects\": [{\"id\": \"DE001\", \"title\": \"Data Pipeline\", \"description\": \"ETL pipeline for real-time data processing\", \"status\": \"active\"}]}]}\u001b[0m\n",
      "\n",
      "Chunk 2: Length 157 chars\n",
      "\u001b[32m{\"technologies\": {\"frameworks\": [\"TensorFlow\", \"PyTorch\", \"scikit-learn\"], \"languages\": [\"Python\", \"R\", \"Julia\"], \"cloud\": [\"AWS\", \"Google Cloud\", \"Azure\"]}}\u001b[0m\n",
      "\n",
      "Chunk 3: Length 82 chars\n",
      "\u001b[34m{\"metadata\": {\"founded\": 2020, \"headquarters\": \"San Francisco\", \"employees\": 150}}\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_chunks(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59fe2b1",
   "metadata": {},
   "source": [
    "### Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2c113ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKDOWN_TEXT = \"\"\"# Artificial Intelligence Overview\n",
    "\n",
    "Artificial intelligence is transforming technology and shaping the future of computing.\n",
    "\n",
    "## Machine Learning\n",
    "\n",
    "Machine learning is a subset of AI that focuses on pattern recognition.\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "Supervised learning algorithms learn from labeled training data.\n",
    "They make predictions based on input-output pairs.\n",
    "\n",
    "Common algorithms include:\n",
    "- Linear regression\n",
    "- Decision trees\n",
    "- Support vector machines\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "Unsupervised learning finds patterns in unlabeled data.\n",
    "It's useful for clustering and dimensionality reduction.\n",
    "\n",
    "Common techniques:\n",
    "- K-means clustering\n",
    "- Principal component analysis\n",
    "- Hierarchical clustering\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "Deep learning uses neural networks with multiple layers.\n",
    "\n",
    "### Neural Networks\n",
    "\n",
    "Neural networks are inspired by biological neurons.\n",
    "They consist of interconnected nodes organized in layers.\n",
    "\n",
    "### Convolutional Neural Networks\n",
    "\n",
    "CNNs excel at image recognition tasks.\n",
    "They use convolutional layers to detect features hierarchically.\n",
    "\n",
    "## Applications\n",
    "\n",
    "AI has applications across multiple domains:\n",
    "\n",
    "### Healthcare\n",
    "\n",
    "- Disease diagnosis\n",
    "- Drug discovery\n",
    "- Medical imaging analysis\n",
    "\n",
    "### Finance\n",
    "\n",
    "- Fraud detection\n",
    "- Algorithmic trading\n",
    "- Risk assessment\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8d0e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f636104",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header_1\"),\n",
    "    (\"##\", \"Header_2\"),\n",
    "    (\"###\", \"Header_3\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d548ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the markdown splitter\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on,\n",
    "    strip_headers=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8061fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Header_1': 'Artificial Intelligence Overview'}, page_content='# Artificial Intelligence Overview  \\nArtificial intelligence is transforming technology and shaping the future of computing.'), Document(metadata={'Header_1': 'Artificial Intelligence Overview', 'Header_2': 'Machine Learning'}, page_content='## Machine Learning  \\nMachine learning is a subset of AI that focuses on pattern recognition.'), Document(metadata={'Header_1': 'Artificial Intelligence Overview', 'Header_2': 'Machine Learning', 'Header_3': 'Supervised Learning'}, page_content='### Supervised Learning  \\nSupervised learning algorithms learn from labeled training data.\\nThey make predictions based on input-output pairs.  \\nCommon algorithms include:\\n- Linear regression\\n- Decision trees\\n- Support vector machines'), Document(metadata={'Header_1': 'Artificial Intelligence Overview', 'Header_2': 'Machine Learning', 'Header_3': 'Unsupervised Learning'}, page_content=\"### Unsupervised Learning  \\nUnsupervised learning finds patterns in unlabeled data.\\nIt's useful for clustering and dimensionality reduction.  \\nCommon techniques:\\n- K-means clustering\\n- Principal component analysis\\n- Hierarchical clustering\"), Document(metadata={'Header_1': 'Artificial Intelligence Overview', 'Header_2': 'Deep Learning'}, page_content='## Deep Learning  \\nDeep learning uses neural networks with multiple layers.'), Document(metadata={'Header_1': 'Artificial Intelligence Overview', 'Header_2': 'Deep Learning', 'Header_3': 'Neural Networks'}, page_content='### Neural Networks  \\nNeural networks are inspired by biological neurons.\\nThey consist of interconnected nodes organized in layers.'), Document(metadata={'Header_1': 'Artificial Intelligence Overview', 'Header_2': 'Deep Learning', 'Header_3': 'Convolutional Neural Networks'}, page_content='### Convolutional Neural Networks  \\nCNNs excel at image recognition tasks.\\nThey use convolutional layers to detect features hierarchically.'), Document(metadata={'Header_1': 'Artificial Intelligence Overview', 'Header_2': 'Applications'}, page_content='## Applications  \\nAI has applications across multiple domains:'), Document(metadata={'Header_1': 'Artificial Intelligence Overview', 'Header_2': 'Applications', 'Header_3': 'Healthcare'}, page_content='### Healthcare  \\n- Disease diagnosis\\n- Drug discovery\\n- Medical imaging analysis'), Document(metadata={'Header_1': 'Artificial Intelligence Overview', 'Header_2': 'Applications', 'Header_3': 'Finance'}, page_content='### Finance  \\n- Fraud detection\\n- Algorithmic trading\\n- Risk assessment')]\n"
     ]
    }
   ],
   "source": [
    "# split the text\n",
    "\n",
    "markdown_chunks = markdown_splitter.split_text(MARKDOWN_TEXT)\n",
    "\n",
    "print(markdown_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f649127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Artificial Intelligence Overview  \n",
      "Artificial intelligence is transforming technology and shaping the future of computing.\n",
      "\n",
      "## Machine Learning  \n",
      "Machine learning is a subset of AI that focuses on pattern recognition.\n",
      "\n",
      "### Supervised Learning  \n",
      "Supervised learning algorithms learn from labeled training data.\n",
      "They make predictions based on input-output pairs.  \n",
      "Common algorithms include:\n",
      "- Linear regression\n",
      "- Decision trees\n",
      "- Support vector machines\n",
      "\n",
      "### Unsupervised Learning  \n",
      "Unsupervised learning finds patterns in unlabeled data.\n",
      "It's useful for clustering and dimensionality reduction.  \n",
      "Common techniques:\n",
      "- K-means clustering\n",
      "- Principal component analysis\n",
      "- Hierarchical clustering\n",
      "\n",
      "## Deep Learning  \n",
      "Deep learning uses neural networks with multiple layers.\n",
      "\n",
      "### Neural Networks  \n",
      "Neural networks are inspired by biological neurons.\n",
      "They consist of interconnected nodes organized in layers.\n",
      "\n",
      "### Convolutional Neural Networks  \n",
      "CNNs excel at image recognition tasks.\n",
      "They use convolutional layers to detect features hierarchically.\n",
      "\n",
      "## Applications  \n",
      "AI has applications across multiple domains:\n",
      "\n",
      "### Healthcare  \n",
      "- Disease diagnosis\n",
      "- Drug discovery\n",
      "- Medical imaging analysis\n",
      "\n",
      "### Finance  \n",
      "- Fraud detection\n",
      "- Algorithmic trading\n",
      "- Risk assessment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in markdown_chunks:\n",
    "    print(doc.page_content, end=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-text-splitters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
